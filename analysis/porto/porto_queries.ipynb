{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "tqdm.pandas()\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_location = \"./final_data.csv\"\n",
    "df = pd.read_csv(csv_location)\n",
    "df['TIMESTAMP'] = pd.to_datetime(df.TIMESTAMP, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>CAMERA_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:00:18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:00:33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:03:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:03:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:03:33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:03:48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:04:03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:04:18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:04:33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 20:04:48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TAXI_ID           TIMESTAMP  CAMERA_ID\n",
       "0        0 2013-08-13 20:00:18          0\n",
       "1        0 2013-08-13 20:00:33          0\n",
       "2        0 2013-08-13 20:03:03          1\n",
       "3        0 2013-08-13 20:03:18          1\n",
       "4        0 2013-08-13 20:03:33          2\n",
       "5        0 2013-08-13 20:03:48          2\n",
       "6        0 2013-08-13 20:04:03          3\n",
       "7        0 2013-08-13 20:04:18          3\n",
       "8        0 2013-08-13 20:04:33          3\n",
       "9        0 2013-08-13 20:04:48          3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_LIMIT = 10 # for quick testing... -1 to look at all data.. 10 to look at first 10 rows\n",
    "chunk_size = 15 # only seconds!\n",
    "max_row = 3\n",
    "\n",
    "# based on 99th percentile! these are in terms of seconds\n",
    "rhos = {0: 135, 1: 90, 2: 90, 3: 240, 4: 210, 5: 120, 6: 150, 7: 180, 8: 300, 9: 90, 10: 45, 11: 255, 12: 150, 13: 180, 14: 165, 15: 150, 16: 165, 17: 210, 18: 165, 19: 210, 20: 135, 21: 150, 22: 210, 23: 120, 24: 90, 25: 180, 26: 135, 27: 195, 28: 195, 29: 300, 30: 155, 31: 135, 32: 75, 33: 120, 34: 120, 35: 90, 36: 135, 37: 75, 38: 90, 39: 150, 40: 60, 41: 90, 42: 210, 43: 210, 44: 195, 45: 165, 46: 60, 47: 105, 48: 90, 49: 135, 50: 75, 51: 135, 52: 150, 53: 180, 54: 195, 55: 210, 56: 90, 57: 90, 58: 15, 59: 15, 60: 45, 61: 120, 62: 225, 63: 195, 64: 105, 65: 210, 66: 135, 67: 195, 68: 315, 69: 135, 70: 45, 71: 323, 72: 315, 73: 450, 74: 210, 75: 225, 76: 135, 77: 180, 78: 120, 79: 255, 80: 315, 81: 105, 82: 240, 83: 525, 84: 165, 85: 276, 86: 210, 87: 210, 88: 150, 89: 483, 90: 135, 91: 105, 92: 135, 93: 180, 94: 225, 95: 210, 96: 15, 97: 180, 98: 212, 99: 247, 100: 210, 101: 97, 102: 135, 103: 285, 104: 138}\n",
    "\n",
    "max_num_unique_taxis = 300\n",
    "num_days = None # set later in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_for_camera(CAMERA_ID, privid=True):\n",
    "    if not privid:\n",
    "        cam_df = df[df['CAMERA_ID'] == CAMERA_ID][[\"TAXI_ID\", \"TIMESTAMP\"]]\n",
    "        temp_cam_df = cam_df.sort_values(\"TIMESTAMP\")[:HEAD_LIMIT] \n",
    "        return temp_cam_df.copy()\n",
    "    cam_df = df[df['CAMERA_ID'] == CAMERA_ID][[\"TAXI_ID\", \"TIMESTAMP\"]]\n",
    "    temp_cam_df = cam_df.sort_values(\"TIMESTAMP\")[:HEAD_LIMIT] \n",
    "    freq = str(chunk_size) + \"s\"\n",
    "    f = temp_cam_df.groupby(pd.Grouper(key=\"TIMESTAMP\", freq=freq))['TAXI_ID'].progress_apply(lambda e : list(np.unique(e))[:max_row])\n",
    "    g = f.explode()\n",
    "    y = g[g.notnull()]\n",
    "    y = y.reset_index()\n",
    "    return y.copy()\n",
    "\n",
    "def get_durs(y, upper, privid=True):\n",
    "    y = y.drop_duplicates([\"TIMESTAMP\", \"TAXI_ID\"])\n",
    "    z = y.groupby([y['TIMESTAMP'].dt.date, \"TAXI_ID\"])[\"TIMESTAMP\"].agg([np.min, np.max])\n",
    "    z['dur'] = z['amax'] - z['amin']\n",
    "    z['dur'] = z['dur'].apply(lambda x : x.total_seconds())\n",
    "    n = z.reset_index()\n",
    "    if privid:\n",
    "        avg_per_day = (n.groupby(\"TIMESTAMP\")[\"dur\"].sum()/max_num_unique_taxis).clip(upper=upper*3600)\n",
    "        avg_avg = avg_per_day.sum()/num_days/3600\n",
    "    else:\n",
    "        avg_per_day = n.groupby(\"TIMESTAMP\")[\"dur\"].mean()\n",
    "        avg_avg = avg_per_day.mean()/3600\n",
    "    return avg_avg\n",
    "\n",
    "def get_taxi_counts_per_day(y, privid=True):\n",
    "    temp = y.groupby('date')[\"TAXI_ID\"].nunique()\n",
    "    if privid:\n",
    "        avg = np.sum(temp)/num_days\n",
    "    else:\n",
    "        avg = np.mean(temp)\n",
    "    return avg\n",
    "\n",
    "def get_per_table_sensitivity(rho):\n",
    "    return (math.ceil(rho/chunk_size)+1) * max_row\n",
    "\n",
    "def prep_table_for_taxi_counts(h):\n",
    "    h['date'] = h[\"TIMESTAMP\"].dt.date\n",
    "    h = h.drop_duplicates([\"date\", \"TAXI_ID\"])\n",
    "    h = h.drop(columns=[\"TIMESTAMP\"])\n",
    "    return h\n",
    "    \n",
    "def get_union_table_sensitivity(s1, s2):\n",
    "    return s1 + s2\n",
    "\n",
    "def get_intersection_table_sensitivity(s1, s2):\n",
    "    return s1 + s2\n",
    "\n",
    "# def get_noise_scale(tot_sensitivity, upper, denom):\n",
    "#     return (tot_sensitivity * upper)/denom\n",
    "\n",
    "def get_acc_and_std(truth, privid_prenoise, noise_scale, num_samples=1000):\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        noise = np.random.laplace(loc=0, scale=noise_scale, size=1)[0]\n",
    "        samples.append((1 - abs(privid_prenoise+noise-truth) / truth) * 100)\n",
    "    print(\"%.2f%% +/- %.2f%%\" % (np.mean(samples), np.std(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [00:00<00:00, 10808.63it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 10096.32it/s]\n"
     ]
    }
   ],
   "source": [
    "cam27table = get_table_for_camera(27)\n",
    "cam10table = get_table_for_camera(10)\n",
    "gt_cam27table = get_table_for_camera(27, privid=False)\n",
    "gt_cam10table = get_table_for_camera(10, privid=False)\n",
    "\n",
    "# union em!\n",
    "merged = pd.concat([cam27table, cam10table])\n",
    "gt_merged = pd.concat([gt_cam27table, gt_cam10table])\n",
    "\n",
    "num_days = (merged[\"TIMESTAMP\"].dt.date.max()-merged[\"TIMESTAMP\"].dt.date.min()).days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>TAXI_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-01 00:14:15</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-01 00:14:30</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-01 00:28:00</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-01 00:28:30</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-01 00:28:45</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-07-01 00:29:00</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-07-01 00:29:15</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-07-01 02:00:45</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-07-01 02:01:00</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-07-01 02:01:15</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TIMESTAMP TAXI_ID\n",
       "0 2013-07-01 00:14:15     257\n",
       "1 2013-07-01 00:14:30     257\n",
       "2 2013-07-01 00:28:00     257\n",
       "3 2013-07-01 00:28:30     257\n",
       "4 2013-07-01 00:28:45     257\n",
       "5 2013-07-01 00:29:00     257\n",
       "6 2013-07-01 00:29:15     257\n",
       "7 2013-07-01 02:00:45     158\n",
       "8 2013-07-01 02:01:00     158\n",
       "9 2013-07-01 02:01:15     158"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam27table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_rho_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7b70cdec3466>:23: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  avg_avg = avg_per_day.sum()/num_days/3600\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a87ddb6cc1f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrho2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_per_table_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0munion_rho_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_union_table_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnoise_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munion_rho_sum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num_unique_taxis\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# todo: set seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Avg Working Hours of Taxi... Via Union of 2 Cameras\n",
    "\n",
    "upper = 16\n",
    "\n",
    "avg_duration = get_durs(merged, upper)\n",
    "avg_duration_gt = get_durs(merged, None, privid=False)\n",
    "rho1 = get_per_table_sensitivity(rhos[27])\n",
    "rho2 = get_per_table_sensitivity(rhos[10])\n",
    "union_rho_sum = get_union_table_sensitivity(rho1, rho2)\n",
    "noise_scale = (union_rho_sum * upper)/(max_num_unique_taxis * num_days)\n",
    "noise = round(np.random.laplace(loc=0, scale=noise_scale, size=1)[0], 5) # todo: set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.862617862371253, 6.206143734737484, -0.00108, 0.00791, 364)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_duration_gt, avg_duration, noise, round(noise_scale, 5), num_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.14% +/- 0.18%\n"
     ]
    }
   ],
   "source": [
    "# min(avg_duration+noise, avg_duration_gt)/max(avg_duration+noise, avg_duration_gt)\n",
    "get_acc_and_std(avg_duration_gt, avg_duration, noise_scale)\n",
    "# 94.14% +/- 0.18%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Num Taxis Present in Both Cameras Each\n",
    "\n",
    "table1 = prep_table_for_taxi_counts(cam27table.copy())\n",
    "table2 = prep_table_for_taxi_counts(cam10table.copy())\n",
    "\n",
    "gt_table1 = prep_table_for_taxi_counts(gt_cam27table.copy())\n",
    "gt_table2 = prep_table_for_taxi_counts(gt_cam10table.copy())\n",
    "\n",
    "# intersect\n",
    "y = pd.merge(table1,table2,on=['TAXI_ID', 'date'])\n",
    "gt_y = pd.merge(gt_table1,gt_table2,on=['TAXI_ID', 'date'])\n",
    "\n",
    "avg_count = get_taxi_counts_per_day(y)\n",
    "gt_avg_count = get_taxi_counts_per_day(gt_y, False)\n",
    "\n",
    "rho1 = get_per_table_sensitivity(rhos[27])\n",
    "rho2 = get_per_table_sensitivity(rhos[10])\n",
    "intersect_rho_sum = get_intersection_table_sensitivity(rho1, rho2)\n",
    "noise_scale = intersect_rho_sum * 1 / num_days\n",
    "noise = round(np.random.laplace(loc=0, scale=noise_scale, size=1)[0], 5) # todo: set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131.25753424657535, 131.48901098901098, -0.09335, 0.14835, 364)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_avg_count, avg_count, noise, round(noise_scale, 5), num_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.80% +/- 0.13%\n"
     ]
    }
   ],
   "source": [
    "# min(avg_count+noise, gt_avg_count)/max(avg_count+noise, gt_avg_count)\n",
    "get_acc_and_std(gt_avg_count, avg_count, noise_scale)\n",
    "# 99.80% +/- 0.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:16<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 254), (20, 253), (27, 239), (11, 215), (6, 212)]\n",
      "[(20, 254), (0, 254), (27, 239), (11, 216), (6, 213)]\n"
     ]
    }
   ],
   "source": [
    "# arxmax query\n",
    "results = dict()\n",
    "for CAMERA_ID in tqdm(df['CAMERA_ID'].unique()):\n",
    "    cam_df = df[df['CAMERA_ID'] == CAMERA_ID][[\"TAXI_ID\", \"TIMESTAMP\"]].copy()\n",
    "    temp_cam_df = cam_df.sort_values(\"TIMESTAMP\")[:HEAD_LIMIT] \n",
    "    temp_cam_df['date'] = temp_cam_df['TIMESTAMP'].dt.date\n",
    "    temp_cam_df = temp_cam_df.drop(columns=['TIMESTAMP'])\n",
    "    temp_cam_df = temp_cam_df.drop_duplicates(['TAXI_ID', 'date'])\n",
    "    avg = np.mean(np.array(temp_cam_df.groupby([\"date\"]).nunique()['TAXI_ID']))\n",
    "    results[CAMERA_ID] = int(avg)\n",
    "chunk_size=15\n",
    "final = dict()\n",
    "for k, v in gt.items():\n",
    "    ns = (math.ceil(rhos[k]/chunk_size) + 1)*max_row/365\n",
    "    final[k] = int(v +  np.random.laplace(loc=0, scale=ns, size=1)[0])\n",
    "print(sorted(final.items(), key=itemgetter(1))[::-1][:5])\n",
    "print(sorted(gt.items(), key=itemgetter(1))[::-1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('364 days 23:57:57')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['TIMESTAMP'].max() - df['TIMESTAMP'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7f5c5e0f9929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_row\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m365\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "(math.ceil(rhos[k]/chunk_size) + 1)*max_row/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
